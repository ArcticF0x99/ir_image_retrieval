{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424c85fc-a075-45d0-9a76-70b94b38f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3 MB 4.0 MB/s eta 0:00:01     |██████████████████████████████▉ | 6.1 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "\u001b[K     |████████████████████████████████| 190 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[K     |████████████████████████████████| 757 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (5.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.12.0 regex-2022.10.31 tokenizers-0.13.2 transformers-4.26.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c5ea23-0a96-41b7-8fb3-1acc1b845968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python directory\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c159e7d1-8e5c-4aa7-9af0-c1afa9c10974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████████████████████████████████████| 1.15k/1.15k [00:00<00:00, 259kB/s]\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|█████████████████████████████████████████| 1.63G/1.63G [03:44<00:00, 7.27MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|███████████████████████████████████████████| 26.0/26.0 [00:00<00:00, 11.1kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|████████████████████████████████████████████| 899k/899k [00:00<00:00, 903kB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|████████████████████████████████████████████| 456k/456k [00:00<00:00, 751kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████████████████████████████████████| 1.36M/1.36M [00:02<00:00, 667kB/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "#https://huggingface.co/facebook/bart-large-mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262ed114-4803-4f52-a6ce-969f576a5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory, output_directory = '/workspace/dataset22/', '/workspace/dataset22/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8f2176a-a672-4383-bb46-fb4a3662fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image text\n",
    "# We use some very baseline method to get a textual representation: we just use the text of the pages that contain the image.\n",
    "def load_image_text(image_id):\n",
    "    ret = ''\n",
    "    for txt_file in glob(input_directory +'/images/' + image_id[:3] + '/' + image_id + '/*/*/*/text.txt'):\n",
    "        ret += '\\n\\n' + open(txt_file).read()\n",
    "    return ret.strip()\n",
    "\n",
    "def load_queries():\n",
    "    file_name = input_directory + 'topics-task3.xml'\n",
    "    \n",
    "    if not os.path.exists(file_name):\n",
    "        raise ValueError(f'Could not find the file \"{file_name}\". Got: {glob(input_directory + \"/*\")}')\n",
    "    \n",
    "    topics = pd.read_xml(file_name)\n",
    "    \n",
    "    ret = pd.DataFrame()\n",
    "    # https://github.com/terrier-org/pyterrier/issues/62\\n\",\n",
    "    ret['query'] = topics['title'].apply(lambda i: \"\".join([x if x.isalnum() else \" \" for x in i]))\n",
    "    ret['qid'] = topics['number']\n",
    "    return ret\n",
    "\n",
    "\n",
    "def determine_stance(text, query):\n",
    "    labels = [\"contra \"+ query, \"pro \"+ query, \"neutral \"+ query]\n",
    "    result = classifier(text, labels)\n",
    "    # sorts the labels starting with the most likely\n",
    "    if result[\"labels\"][0].startswith(\"contra\"):\n",
    "        return \"contra\", result[\"scores\"][0]\n",
    "    elif result[\"labels\"][0].startswith(\"pro\"):\n",
    "        return \"pro\", result[\"scores\"][0]\n",
    "    else: \n",
    "        return \"neutral\", result[\"scores\"][0]\n",
    "    \n",
    "\n",
    "def detect_stance_for_image_ids_and_return_best_x_results_for_each_side(image_ids, query, x):\n",
    "    # get image ids from preranking\n",
    "    # get image texts based on preranking \n",
    "    pro_imgs = {}\n",
    "    contra_imgs = {}\n",
    "    for image_id in image_ids:\n",
    "        text = load_image_text(image_id)\n",
    "        # deploy model\n",
    "        stance, score = determine_stance(text, query)\n",
    "        print(image_id, stance, score)\n",
    "        # separate pro and con texts; sort out neutral texts\n",
    "        if stance == \"pro\":\n",
    "            pro_imgs[image_id] = score\n",
    "        elif stance == \"contra\": \n",
    "            contra_imgs[image_id] = score\n",
    "        # sort according to scores\n",
    "        sorted_pro = dict(sorted(pro_imgs.items(), key=lambda x:x[1], reverse=True))\n",
    "        sorted_contra = dict(sorted(contra_imgs.items(), key=lambda x:x[1], reverse=True))\n",
    "        # return best x results for each side\n",
    "        pro_ids = []\n",
    "        contra_ids = []\n",
    "        i = 0\n",
    "        for key in sorted_pro:\n",
    "            if i < len(sorted_pro.keys()) and i < x:\n",
    "                pro_ids.append(key)\n",
    "            else: \n",
    "                break\n",
    "            i += 1\n",
    "        i = 0\n",
    "        for key in sorted_contra:\n",
    "            if i < len(sorted_contra.keys()) and i < x:\n",
    "                contra_ids.append(key)\n",
    "            else: \n",
    "                break\n",
    "            i += 1\n",
    "    return pro_ids, contra_ids\n",
    "# not sorted right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d24439c5-d821-4176-9ec0-4af11318653b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15/562382787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7406f86-23b5-457b-b914-eb3c3bd7ffae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find the file \"/workspace/dataset22/topics-task3.xml\". Got: ['/workspace/dataset22/images']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15/558956450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_queries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15/3326644564.py\u001b[0m in \u001b[0;36mload_queries\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Could not find the file \"{file_name}\". Got: {glob(input_directory + \"/*\")}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find the file \"/workspace/dataset22/topics-task3.xml\". Got: ['/workspace/dataset22/images']"
     ]
    }
   ],
   "source": [
    "queries = load_queries()  \n",
    "queries.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d163b28-a0f0-437f-baad-437b6bac94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = os.listdir(input_directory +'/images/' + \"I00\")[0:10] #[\"I00\", \"I01\",\"I02\", \"I03\", \"I04\", \"I05\", \"I06\"]\n",
    "query = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5815ac76-26cd-4502-97b2-accf43f3857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I000330ba4ea0ad13 contra 0.4679756462574005\n",
      "I000d8de9c4746ee9 pro 0.3815423846244812\n",
      "I0010d5b5473065fa pro 0.6040793061256409\n",
      "I001652ec040f07c4 pro 0.4360259473323822\n",
      "I001a318b3176d501 pro 0.379162460565567\n",
      "I001b3068979b8629 pro 0.4018160402774811\n",
      "I001c2de5ef28f77f pro 0.4739639461040497\n",
      "I001d567f0fb443d7 neutral 0.3531545400619507\n",
      "I00246a6916fec768 pro 0.3388685882091522\n",
      "I0024c0097c425855 pro 0.38304683566093445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['I0010d5b5473065fa', 'I001c2de5ef28f77f'], ['I000330ba4ea0ad13'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_stance_for_image_ids_and_return_best_x_results_for_each_side(test_ids, query, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b179fe82-46c3-4205-9c42-d5ee18781622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Abortion is a universal right.',\n",
       " 'labels': ['pro abortion', 'neutral abortion', 'contra abortion'],\n",
       " 'scores': [0.8498501777648926, 0.1026904508471489, 0.04745934531092644]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"Abortion is a universal right.\"\n",
    "candidate_labels = ['pro abortion', 'contra abortion', 'neutral abortion']\n",
    "classifier(sequence_to_classify, candidate_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
