{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7cf14b-e71b-46e0-b441-2654e6315661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from tira_utils import get_input_directory_and_output_directory, normalize_run\n",
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "from PIL import Image\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from preselection import retrieve\n",
    "from phrase_generation import generate_phrases\n",
    "from typing import Tuple\n",
    "from typing_extensions import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026bfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "transformers.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee342c-7dd2-48f8-bcf8-d6df4fcf10a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir, output_dir = get_input_directory_and_output_directory(default_input='/workspace/dataset23/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3748110-b9d8-4b92-8ebc-ff7c5c51accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('image_results').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ea1f0-0ca5-4c1f-8823-78d2364a33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries_xml():\n",
    "    file_name = glob(input_dir + '/*.xml')[0]\n",
    "    \n",
    "    topics = pd.read_xml(file_name)\n",
    "    \n",
    "    ret = pd.DataFrame()\n",
    "    # https://github.com/terrier-org/pyterrier/issues/62\\n\",\n",
    "    ret['query'] = topics['title'].apply(lambda i: \"\".join([x if x.isalnum() else \" \" for x in i]))\n",
    "    ret['qid'] = topics['number']\n",
    "    return ret\n",
    "\n",
    "def load_queries_trecxml():\n",
    "    file_name = glob(input_dir + '/*.xml')[0]\n",
    "    topics = pt.io.read_topics(file_name, format='trecxml')\n",
    "    return topics\n",
    "\n",
    "def load_queries_jsonl():\n",
    "    file_name = glob(input_dir + '/*.jsonl')[0]\n",
    "    return pd.read_json(file_name, lines=True)\n",
    "\n",
    "def load_queries():\n",
    "    try:\n",
    "        return load_queries_xml()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        return load_queries_trecxml()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        return load_queries_jsonl()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    raise Exception(f'Found no topics file. Got: {glob(input_dir + \"/*\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275eb00-38c9-4f44-8e93-4409a0c83642",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model='/workspace/bart-large-mnli', accelerator=\"bettertransformer\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b80948-c32c-4a7d-908a-0b1ec8eb4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_directory_len = len(glob(input_dir+'/images/*')[0].split('/')[-1])\n",
    "\n",
    "# load image text\n",
    "# We use some very baseline method to get a textual representation: we just use the text of the pages that contain the image.\n",
    "def load_website_text(image_id):\n",
    "    ret = ''\n",
    "    for txt_file in glob(input_dir +'/images/' + image_id[:first_directory_len] + '/' + image_id + '/*/*/*/text.txt'):\n",
    "        ret += '\\n\\n' + open(txt_file).read()\n",
    "    return ret.strip()\n",
    "\n",
    "def load_image_text(image_id):\n",
    "    ret = ''\n",
    "    for txt_file in glob(input_dir +'/images/' + image_id[:first_directory_len] + '/' + image_id + '/image-text.txt'):\n",
    "        ret += '\\n\\n' + open(txt_file).read()\n",
    "    return ret.strip()\n",
    "\n",
    "Stance = Literal['pro', 'con', 'neutral']\n",
    "\n",
    "def get_stance(text, query) -> Tuple[Stance, float]:\n",
    "    if text == '':\n",
    "        return 'neutral', 1\n",
    "    labels = [\"contra \"+ query, \"pro \"+ query, \"neutral \"+ query]\n",
    "    \n",
    "    result = classifier(text, labels)\n",
    "    # sorts the labels starting with the most likely\n",
    "    if result[\"labels\"][0].startswith(\"contra\"):\n",
    "        return \"contra\", result[\"scores\"][0]\n",
    "    elif result[\"labels\"][0].startswith(\"pro\"):\n",
    "        return \"pro\", result[\"scores\"][0]\n",
    "    else: \n",
    "        return \"neutral\", result[\"scores\"][0]\n",
    "\n",
    "def get_website_stance(image_id, query) -> Tuple[Stance, float]:\n",
    "    text = load_website_text(image_id)\n",
    "    return get_stance(text, query)\n",
    "\n",
    "def get_image_stance(image_id, query) -> Tuple[Stance, float]:\n",
    "    text = load_image_text(image_id)\n",
    "    return get_stance(text, query)\n",
    "\n",
    "def get_stance_from_source(image_id, query, stance_source : Literal['website', 'image', 'both']) -> Tuple[Stance, float]:\n",
    "    if stance_source == 'website':\n",
    "        return get_website_stance(image_id, query)\n",
    "    elif stance_source == 'image':\n",
    "        return get_image_stance(image_id, query)\n",
    "    elif stance_source == 'both':\n",
    "        website_stance, website_score = get_website_stance(image_id, query)\n",
    "        image_stance, image_score = get_image_stance(image_id, query)\n",
    "        if website_stance == 'neutral' and image_stance == 'neutral':\n",
    "            return 'neutral', 1\n",
    "        if 'neutral' == image_stance or 'neutral' == website_stance:\n",
    "            neutral_score = image_score if image_stance == 'neutral' else website_score\n",
    "\n",
    "            other_score = image_score if image_stance != 'neutral' else website_score\n",
    "            other_stance = image_stance if image_stance != 'neutral' else website_stance\n",
    "            \n",
    "            return other_stance, other_score / 2 + ((1 - neutral_score) / 2) / 2\n",
    "        \n",
    "        if image_stance == website_stance:\n",
    "            return image_stance, image_score / 2 + website_score / 2\n",
    "        \n",
    "        return 'neutral', 1\n",
    "            \n",
    "\n",
    "def detect_stance_for_image_ids_and_return_best_x_results_for_each_side(image_ids, query, x, stance_source : Literal['website', 'image', 'both']):\n",
    "    # get image ids from preranking\n",
    "    # get image texts based on preranking \n",
    "    pro_imgs = {}\n",
    "    contra_imgs = {}\n",
    "    pro_ids = []\n",
    "    contra_ids = []\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        \n",
    "        stance, score = get_stance_from_source(image_id, query, stance_source)\n",
    "        \n",
    "        # separate pro and con texts; sort out neutral texts\n",
    "        if stance == \"pro\":\n",
    "            pro_imgs[image_id] = score\n",
    "        elif stance == \"contra\": \n",
    "            contra_imgs[image_id] = score\n",
    "            \n",
    "    # sort according to scores\n",
    "    sorted_pro = dict(sorted(pro_imgs.items(), key=lambda x:x[1], reverse=True))\n",
    "    sorted_contra = dict(sorted(contra_imgs.items(), key=lambda x:x[1], reverse=True))\n",
    "    \n",
    "    # return best x results for each side\n",
    "    i = 0\n",
    "    for key in sorted_pro:\n",
    "        if i < len(sorted_pro.keys()) and i < x:\n",
    "            pro_ids.append(key)\n",
    "        else: \n",
    "            break\n",
    "        i += 1\n",
    "    i = 0\n",
    "    for key in sorted_contra:\n",
    "        if i < len(sorted_contra.keys()) and i < x:\n",
    "            contra_ids.append(key)\n",
    "        else: \n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "    return pro_ids, contra_ids, sorted_pro, sorted_contra\n",
    "# not sorted right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713156e4-36ce-438e-890b-f3cda20695eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(image_ids):\n",
    "    image_paths = []\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        image_paths.append(input_dir + '/images/' + image_id[:first_directory_len] + '/' + image_id + '/image.webp')\n",
    "        \n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd623a-b4f9-4fd2-a793-f75053b00019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_generator():\n",
    "    model_id = \"/workspace/stable-diffusion-v1-4\"\n",
    "    print('torch.cuda.is_available(): ', torch.cuda.is_available())\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, revision=\"fp16\").to('cuda')\n",
    "    \n",
    "    return pipe\n",
    "    \n",
    "\n",
    "\n",
    "def generate_image(pipe, prompt, isrealistic, image_name=None, guidance_scale=20, inference_steps=50):\n",
    "    if isrealistic:\n",
    "        final_prompt = \"a photograph about the topic: \" + prompt\n",
    "    else:\n",
    "        final_prompt = \"an image in comic style about the topic: \" + prompt\n",
    "    \n",
    "    print(final_prompt)\n",
    "    \n",
    "    image = None\n",
    "    \n",
    "    while image == None or not image.getbbox():\n",
    "        image = pipe(final_prompt, guidance_scale=guidance_scale, num_inference_steps=inference_steps).images[0]\n",
    "        # print(not image.getbbox())\n",
    "\n",
    "    if image_name != None:\n",
    "        image.save(\"image_results/\" + image_name + \".png\")\n",
    "    else:\n",
    "        return image\n",
    "    \n",
    "def show_image(image_name):\n",
    "    image = Image.open(\"image_results/\" + image_name + \".png\")\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a5c27-58a2-4cf7-92f0-843c68629332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flann_index_kdtree_matcher(image1, image2):\n",
    "    MIN_MATCH_COUNT = 10\n",
    "    \n",
    "    # Initiate SIFT detector\n",
    "    sift = cv.SIFT_create()\n",
    "    \n",
    "    image1_gray = cv.cvtColor(image1, cv.COLOR_RGB2GRAY)\n",
    "    image2_gray = cv.cvtColor(image2, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(image1_gray, None)\n",
    "    kp2, des2 = sift.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    if des1 is None or des2 is None:\n",
    "        return [], 0\n",
    "            \n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    \n",
    "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    \n",
    "    # Apply ratio test\n",
    "    global good\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append(m)\n",
    "    \n",
    "    if len(good) == 0:\n",
    "        return [], 0\n",
    "    \n",
    "    most_common_keypoint_matches = Counter(x.trainIdx for x in good).most_common(1)[0]\n",
    "    \n",
    "    # single keypoint check for to many matches\n",
    "    if most_common_keypoint_matches[1] > 10:\n",
    "        return [], 0\n",
    "            \n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        \n",
    "        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "        \n",
    "        if M is None:\n",
    "            print(\"empty Homography on image\")\n",
    "            return [], 0\n",
    "        \n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        \n",
    "        h,w, _ = image1.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        dst = cv.perspectiveTransform(pts,M)\n",
    "        image2 = cv.polylines(image2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n",
    "             \n",
    "    else:\n",
    "        # print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "        matchesMask = None\n",
    "\n",
    "    draw_params = dict(matchColor=(0, 255, 0),\n",
    "                       singlePointColor=(255, 0, 0),\n",
    "                       matchesMask=matchesMask,\n",
    "                       flags=cv.DrawMatchesFlags_DEFAULT)\n",
    "    \n",
    "    img_matches = np.empty((max(image1.shape[0], image2.shape[0]), image1.shape[1]+image2.shape[1], 3), dtype=np.uint8)\n",
    "    # img3 = cv.drawMatches(image1, kp1, image2, kp2, good, img_matches, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    img3 = cv.drawMatches(image1, kp1, image2, kp2, good, img_matches, **draw_params)\n",
    "    \n",
    "    # plt.imshow(img3, ), plt.show()\n",
    "    \n",
    "    return img3, len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725fc9b5-3ca4-4d4d-ab38-b7f9465acdf7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sort_images(images, dataframe):\n",
    "    sorted_images = []\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        image_id = dataframe[\"image_num\"][i]\n",
    "        sorted_images.append(images[image_id])\n",
    "    \n",
    "    return sorted_images\n",
    "\n",
    "\n",
    "def rank_images(images, image_name):\n",
    "    print(\"image_results/\" + image_name)\n",
    "    topic_img = cv.cvtColor(cv.imread(\"image_results/\" + image_name), cv.COLOR_BGR2RGB)\n",
    "    image_ids = []\n",
    "    match_numbers = []\n",
    "    img_num = 0\n",
    "\n",
    "    for image in images:\n",
    "        # print(img_num)\n",
    "    \n",
    "        if image.size <= 100000000:\n",
    "            img, good_matches = flann_index_kdtree_matcher(topic_img, image.copy())\n",
    "        \n",
    "            image_ids.append(img_num)\n",
    "            match_numbers.append(good_matches)\n",
    "    \n",
    "        img_num += 1\n",
    "\n",
    "    image_id_and_match_num_dataframe = pd.DataFrame({\"image_id\": image_ids, \"match_num\": match_numbers})\n",
    "    sorted_image_id_and_match_num_dataframe = image_id_and_match_num_dataframe.sort_values(by=['match_num'], ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return sort_images(images, sorted_image_id_and_match_num_dataframe), sorted_image_id_and_match_num_dataframe\n",
    "\n",
    "\n",
    "def update_image_id_and_match_num_dataframe(image_id_and_match_num_dataframe, curr_image_id_and_match_num_dataframe):\n",
    "    for i in range(len(image_id_and_match_num_dataframe)):\n",
    "        image_id = image_id_and_match_num_dataframe.iloc[i][\"image_id\"]\n",
    "        \n",
    "        for j in range(len(curr_image_id_and_match_num_dataframe)): \n",
    "            if image_id == curr_image_id_and_match_num_dataframe.iloc[j][\"image_id\"]:\n",
    "                image_id_and_match_num_dataframe.iloc[i][\"match_num\"] += curr_image_id_and_match_num_dataframe.iloc[j][\"match_num\"]\n",
    "        \n",
    "    return image_id_and_match_num_dataframe\n",
    "\n",
    "\n",
    "def combined_image_ranking(images, old_image_ids, generated_image_names):\n",
    "    image_id_and_match_num_dataframe = pd.DataFrame()\n",
    "    \n",
    "    for generated_image_name in generated_image_names:\n",
    "        generated_image = cv.cvtColor(cv.imread(\"image_results/\" + generated_image_name), cv.COLOR_BGR2RGB)\n",
    "        image_ids = []\n",
    "        match_numbers = []\n",
    "        image_numbers = []\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            if images[i].size <= 100000000:\n",
    "                img, good_matches = flann_index_kdtree_matcher(generated_image, images[i].copy())\n",
    "                \n",
    "                image_numbers.append(i)\n",
    "                image_ids.append(old_image_ids[i])\n",
    "                match_numbers.append(good_matches)\n",
    "        \n",
    "        if image_id_and_match_num_dataframe.empty:\n",
    "            image_id_and_match_num_dataframe = pd.DataFrame({\"image_num\": image_numbers, \"image_id\": image_ids, \"match_num\": match_numbers})\n",
    "        else:\n",
    "            curr_image_id_and_match_num_dataframe = pd.DataFrame({\"image_id\": image_ids, \"match_num\": match_numbers})\n",
    "            image_id_and_match_num_dataframe = update_image_id_and_match_num_dataframe(image_id_and_match_num_dataframe, curr_image_id_and_match_num_dataframe)\n",
    "    \n",
    "    sorted_image_id_and_match_num_dataframe = image_id_and_match_num_dataframe.sort_values(by=['match_num'], ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return sort_images(images, sorted_image_id_and_match_num_dataframe), sorted_image_id_and_match_num_dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015a2e4-9d91-4126-a389-8e88ad6ad3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_multiple_images(image_list, row_count, col_count, save_image_name=None):\n",
    "    if len(image_list) < row_count:\n",
    "        row_count = len(image_list)\n",
    "    \n",
    "    for i in range(0, len(image_list), row_count*col_count):\n",
    "        fig = plt.figure(figsize=(20, 20), dpi=80)\n",
    "    \n",
    "    for j in range(0, row_count*col_count):\n",
    "        fig.add_subplot(row_count, col_count, j+1)\n",
    "        plt.imshow(image_list[i+j])\n",
    "        \n",
    "    if save_image_name != None:\n",
    "        save_path = \"image_results/\" + save_image_name\n",
    "        plt.savefig(save_path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945f286-8d35-4f1b-81c6-f5240722cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_format_with_dataframe(preselection_data, image_id_dataframe, stance_string, max_image_num, show_submission_format):\n",
    "    submission_format = \"\"\n",
    "    rank = 1\n",
    "    \n",
    "    if len(image_id_dataframe) < max_image_num:\n",
    "        image_num = len(image_id_dataframe)\n",
    "    else:\n",
    "        image_num = max_image_num\n",
    "    \n",
    "    #print(preselection_data['docno'])\n",
    "    \n",
    "    for i in range(image_num):\n",
    "        #print(image_id_dataframe[\"image_id\"][i])\n",
    "        image_data = preselection_data.loc[preselection_data['docno'] == image_id_dataframe[\"image_id\"][i]]\n",
    "        #print(image_data)\n",
    "        \n",
    "        query_id = image_data[\"qid\"].values[0]\n",
    "        stance = stance_string\n",
    "        image_id = image_data[\"docno\"].values[0]\n",
    "        image_rank = rank\n",
    "        image_score = image_num - (rank-1)\n",
    "        method = \"-\"\n",
    "        \n",
    "        submission_format += (str(query_id) + \" \" + str(stance) + \" \" + str(image_id) + \" \" + str(image_rank) + \" \" + str(image_score) + \" \" + str(method) + \"\\n\")\n",
    "        \n",
    "        rank += 1\n",
    "        \n",
    "    if show_submission_format:\n",
    "        print(submission_format)\n",
    "    \n",
    "    return submission_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad70920-ff84-4093-8087-aa2327578441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_rank_images(image_ids, preselection_data, stance_string, pipe, query, max_image_num, should_gen_new_images, show_images, show_submission_format):\n",
    "    image_paths = load_image_paths(image_ids)\n",
    "    images = [cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB) for image_path in image_paths]\n",
    "    print(\"get images\")\n",
    "    \n",
    "    realistic_image_name = \"image_realistic_\" + stance_string\n",
    "    comic_image_name = \"image_comic_\" + stance_string\n",
    "    \n",
    "    if should_gen_new_images:\n",
    "        generate_image(pipe, query, True, realistic_image_name)\n",
    "        show_image(realistic_image_name)\n",
    "        generate_image(pipe, query, False, comic_image_name)\n",
    "        show_image(comic_image_name)\n",
    "        print(\"images generated\")\n",
    "    \n",
    "    realistic_image_name += \".png\"\n",
    "    comic_image_name += \".png\"\n",
    "    ranked_images, sorted_image_id_and_match_num_dataframe = combined_image_ranking(images, image_ids, [realistic_image_name, comic_image_name])\n",
    "    print(\"ranking\")\n",
    "\n",
    "    submission_format = create_submission_format_with_dataframe(preselection_data, sorted_image_id_and_match_num_dataframe, stance_string, max_image_num, show_submission_format)\n",
    "    print(\"submission\")\n",
    "    \n",
    "    if show_images:\n",
    "        show_multiple_images(ranked_images, (max_image_num), 1)\n",
    "        print(\"showed images\")\n",
    "    \n",
    "    return submission_format\n",
    "    \n",
    "\n",
    "def full_pipeline(pipe_id, query_with_qid, stance_string, sd_pipe,  max_image_num=10, should_gen_new_images=True, show_images=False, show_submission_format=True):\n",
    "    local_query_with_qid = query_with_qid.copy()\n",
    "    \n",
    "    print(local_query_with_qid[\"query\"].values[0])\n",
    "    \n",
    "    pos_query, con_query = generate_phrases([str(t) for t in local_query_with_qid[\"query\"].values.tolist()], 'frequency')\n",
    "    \n",
    "    local_query_with_qid[\"query\"].values[0] = pos_query[0]\n",
    "    preselection_data_pro = retrieve(local_query_with_qid)\n",
    "    image_docnos_pro = preselection_data_pro[\"docno\"]\n",
    "    \n",
    "    local_query_with_qid[\"query\"].values[0] = con_query[0]\n",
    "    preselection_data_con = retrieve(local_query_with_qid)\n",
    "    image_docnos_con = preselection_data_con[\"docno\"]\n",
    "    print(\"preselection\")\n",
    "    global pro_ids_image, con_ids_image\n",
    "\n",
    "    if pipe_id == -1:\n",
    "        query_id = list(query_with_qid.qid)[0]\n",
    "        # only preselection (NO image generation)\n",
    "        def get_as_format(docnos : pd.Series, stance : str):\n",
    "            out = ''\n",
    "            docnos = list(list(docnos)[:max_image_num])\n",
    "            for i, docno in enumerate(docnos):\n",
    "                out = f'{out}\\n{query_id} {stance} {docno} {i + 1} {max_image_num - i} -'\n",
    "            return out\n",
    "\n",
    "        \"\"\"51 pro I301888e1ac19d0afb785b997 1 10 -\n",
    "51 pro If0312920d8e2b14e67471275 2 9 -\n",
    "51 pro I3f21e9a1d6b0561f4d2df837 3 8 -\n",
    "51 pro I5223eaa67229e284b12f9414 4 7 -\n",
    "51 pro I3bfb6ac2fd6569e5a1117540 5 6 -\n",
    "51 pro I5bbd8d2edddb14d2ae3b4acc 6 5 -\n",
    "51 pro Ia835fa6e77affcea3505d79d 7 4 -\n",
    "51 pro Ia146f5c11acc7bdcb2621d8b 8 3 -\n",
    "51 pro Iabb7340d2eff5bd66ccfe215 9 2 -\"\"\"\n",
    "        \n",
    "        \n",
    "\n",
    "        return get_as_format(image_docnos_pro, 'pro'), get_as_format(image_docnos_con, 'con')\n",
    "\n",
    "\n",
    "    if pipe_id == 0:\n",
    "        # only preselection + image generation + best match\n",
    "        submission_pipe1_pro = pipe_rank_images(image_docnos_pro, preselection_data_pro, \"pro\", sd_pipe, pos_query[0], max_image_num, should_gen_new_images, show_images, show_submission_format)\n",
    "        submission_pipe1_con = pipe_rank_images(image_docnos_con, preselection_data_con, \"con\", sd_pipe, con_query[0], max_image_num, should_gen_new_images, show_images, show_submission_format)\n",
    "        \n",
    "        return submission_pipe1_pro, submission_pipe1_con\n",
    "    \n",
    "    if pipe_id == 1:\n",
    "        # re-evaluate stance based on web text\n",
    "        pro_ids_web, _, _, _ = detect_stance_for_image_ids_and_return_best_x_results_for_each_side(image_docnos_pro, pos_query[0], max_image_num, 'website')\n",
    "        _, con_ids_web, _, _ = detect_stance_for_image_ids_and_return_best_x_results_for_each_side(image_docnos_con, con_query[0], max_image_num, 'website')\n",
    "        submission_pipe2_pro = pipe_rank_images(pro_ids_web, preselection_data_pro, \"pro\", sd_pipe, pos_query[0], max_image_num, should_gen_new_images, show_images, show_submission_format)\n",
    "        submission_pipe2_con = pipe_rank_images(con_ids_web, preselection_data_con, \"con\", sd_pipe, con_query[0], max_image_num, should_gen_new_images, show_images, show_submission_format)\n",
    "        return submission_pipe2_pro, submission_pipe2_con\n",
    "    \n",
    "    if pipe_id == 2:\n",
    "        # re-evaluate stance based on image text\n",
    "        \n",
    "        pro_ids_image, _, _, _ = detect_stance_for_image_ids_and_return_best_x_results_for_each_side(image_docnos_pro, pos_query[0], max_image_num, 'image')\n",
    "        _, con_ids_image, _, _ = detect_stance_for_image_ids_and_return_best_x_results_for_each_side(image_docnos_con, con_query[0], max_image_num, 'image')\n",
    "        print('pro_ids_web', pro_ids_image)\n",
    "        submission_pipe3_pro = pipe_rank_images(pro_ids_image, preselection_data_pro, \"pro\", sd_pipe, pos_query[0], max_image_num, should_gen_new_images, show_images, show_submission_format)\n",
    "        submission_pipe3_con = pipe_rank_images(con_ids_image, preselection_data_con, \"con\", sd_pipe, con_query[0], max_image_num, should_gen_new_images, show_images, show_submission_format)\n",
    "        \n",
    "        return submission_pipe3_pro, submission_pipe3_con\n",
    "    \n",
    "    if pipe_id == 3:\n",
    "        # combine stance from web and image\n",
    "        pro_ids_image, _, _, _ = detect_stance_for_image_ids_and_return_best_x_results_for_each_side(image_docnos_pro, pos_query[0], max_image_num, 'both')\n",
    "        _, con_ids_image, _, _ = detect_stance_for_image_ids_and_return_best_x_results_for_each_side(image_docnos_con, con_query[0], max_image_num, 'both')\n",
    "        print('pro_ids_web', pro_ids_image)\n",
    "        submission_pipe4_pro = pipe_rank_images(pro_ids_image, preselection_data_pro, \"pro\", sd_pipe, pos_query[0], max_image_num, should_gen_new_images, show_images, show_submission_format)\n",
    "        submission_pipe4_con = pipe_rank_images(con_ids_image, preselection_data_con, \"con\", sd_pipe, con_query[0], max_image_num, should_gen_new_images, show_images, show_submission_format)\n",
    "        \n",
    "        return submission_pipe4_pro, submission_pipe4_con\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21745caf-5b28-4be4-9fe8-842de7476d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_pipe = load_image_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e8377-75b5-4d48-acc0-cf86c1ac5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346f881-3498-4878-a87e-1051e02b686a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(output_dir + '/run.txt', 'w') as output_file:\n",
    "    max_queries = int(os.environ.get('MAX_QUERIES', 100))\n",
    "    query_count = min(max_queries, queries.shape[0])\n",
    "    pipeline_id = int(os.environ.get('PIPELINE_ID', 1))\n",
    "    for i in range(query_count):\n",
    "        selected_query_with_qid = queries.iloc[[i]]\n",
    "        pro, con = full_pipeline(pipeline_id, selected_query_with_qid, \"pro\", diff_pipe, max_image_num=10, should_gen_new_images=True, show_images=False, show_submission_format=False)\n",
    "        output_file.write(pro)\n",
    "        output_file.write(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finished pipepline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
