{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk beautifulsoup4 wordfreq spacy matplotlib scikit-learn textblob spacytextblob gensim --quiet --quiet\n",
    "!python -m spacy download en_core_web_lg\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('topics-task3.xml', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = BeautifulSoup(data, \"xml\")\n",
    "topics = [tags.findAll(text=True)[0] for tags in  data.findAll('title', text=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pylab\n",
    "from wordfreq import zipf_frequency, word_frequency\n",
    "\n",
    "\n",
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_ + '\\n' + str(zipf_frequency(str(node.orth_).lower(), 'en')), [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_ + '\\n' + str(zipf_frequency(str(node.orth_).lower(), 'en'))\n",
    "\n",
    "\n",
    "cluster_count = 2\n",
    "km = KMeans(n_clusters=cluster_count)\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "cm = pylab.get_cmap('gist_rainbow')\n",
    "\n",
    "\n",
    "\n",
    "# see following code for 5.5 zipf threshold\n",
    "# docs = list(nlp.pipe((str(t) for t in topics)))\n",
    "# tokens = [token.lemma_ for doc in docs for token in doc if token.pos_ != 'PUNCT']\n",
    "# frequencies = np.array([zipf_frequency(t, 'en') for t in tokens])\n",
    "# labels = km.fit(frequencies.reshape(-1, 1)).labels_\n",
    "# plt.scatter(frequencies, len(frequencies) * [1], color=np.array([cm(1.*l/cluster_count) for l in labels]))\n",
    "# plt.xlim(5.4, 5.6)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "for t in topics[:20]:\n",
    "    t = str(t)\n",
    "    doc = nlp(t)\n",
    "    words = [(str(x), zipf_frequency(str(x), 'en'), x.pos_) for x in doc]\n",
    "    words.sort(key= lambda w: w[1])\n",
    "    frequencies = [zipf_frequency(str(x), 'en') for x in doc]\n",
    "    frequencies = np.array([f for f in frequencies if f > 0])\n",
    "    \n",
    "    plt.scatter(frequencies, len(frequencies) * [1], color=[cm(0 if f < 5.5 else 0.5) for f in frequencies])\n",
    "    plt.show()\n",
    "    #print([s[0] for s in words if s[2] == 'NOUN'])\n",
    "    print(words)\n",
    "    [to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34057117\n",
      "0.5165411\n"
     ]
    }
   ],
   "source": [
    "print(glove_vectors.similarity('ban', 'yes'))\n",
    "print(glove_vectors.similarity('ban', 'no'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we need sex education in schools? -> need 0.0 | sex education schools\n",
      "Should stem cell research be expanded? -> expand 0.0 | stem cell research expanded\n",
      "Should blood donations be financially compensated? -> compensate 0.0 | blood donations financially compensated\n",
      "Should suicide be a criminal offense? -> be 0.0 | suicide criminal offense\n",
      "Should agricultural subsidies be reduced? -> reduce 0.0 | agricultural subsidies reduced\n",
      "Should vigilantism be legal? -> be 0.0 | vigilantism legal\n",
      "Are gender or racial quotas effective? -> be 0.0 | gender racial quotas effective\n",
      "Should holders of public offices resign on bad approval ratings? -> resign 0.0 | holders public offices bad approval ratings\n",
      "Should nuclear weapons be abolished? -> abolish 0.0 | nuclear weapons abolished\n",
      "Should the press be subsidized? -> subsidize 0.0 | press subsidized\n",
      "Is wind power the best alternative energy source? -> be 0.0 | wind power alternative energy source\n",
      "Is utilitarianism morally acceptable? -> be 0.0 | utilitarianism morally acceptable\n",
      "Is capitalism the best form of economy? -> be 0.0 | capitalism form economy\n",
      "Should music that glorifies violence against women be banned? -> ban 0.0 | music glorifies violence women banned\n",
      "Should we imprison fewer people? -> imprison 0.0 | fewer\n",
      "Is hell a real place? -> be 0.0 | hell\n",
      "Can terrorism be justified? -> justify 0.4 | terrorism justified\n",
      "Should celibacy be abolished? -> abolish 0.0 | celibacy abolished\n",
      "Do animals have rights? -> have 0.0 | animals rights\n",
      "Is feminism still needed? -> need 0.0 | feminism needed\n",
      "Do politicians have no right to privacy? -> have 0.0 | politicians privacy\n",
      "Should Scotland become independent? -> become 0.0 | Scotland independent\n",
      "Should endangered species be protected? -> protect 0.0 | endangered species protected\n",
      "Should all museums be free of charge? -> be 0.0 | museums charge\n",
      "Do humans have free will? -> have 0.0 | humans\n",
      "Are video games art? -> be 0.0 | video games art\n",
      "Should humans attempt to contact extra-terrestrial life? -> attempt 0.0 | humans contact extra - terrestrial\n",
      "Is psychology a science? -> be 0.0 | psychology science\n",
      "Is chess a sport? -> be 0.0 | chess sport\n",
      "Are social media platforms doing enough to prevent cyberbullying? -> do 0.0 | social media platforms enough prevent cyberbullying\n",
      "Is genetically modified food unsafe? -> be 0.0 | genetically modified food unsafe\n",
      "Does poverty cause crime? -> cause 0.0 | poverty crime\n",
      "Does legal prostitution increase human trafficking? -> increase 0.0 | legal prostitution human trafficking\n",
      "Is the earth flat? -> be 0.0 | earth flat\n",
      "Should human cloning be banned? -> ban 0.0 | human cloning banned\n",
      "Is communism better than democracy? -> be 0.0 | communism democracy\n",
      "Are gas prices too high? -> be 0.0 | gas prices\n",
      "Should Turkey join the EU? -> join 0.0 | Turkey EU\n",
      "Should hate speech be penalized more? -> hate -0.8 | speech penalized\n",
      "Was the Iraq war legal? -> be 0.0 | Iraq war legal\n",
      "Should bullfighting be banned? -> ban 0.0 | bullfighting banned\n",
      "Should the UNO become a world government? -> become 0.0 | UNO government\n",
      "Should nuclear waste be stored in old salt mines? -> store 0.0 | nuclear waste stored salt mines\n",
      "Should children have mobile phones? -> have 0.0 | children mobile phones\n",
      "Should the inheritance tax be raised? -> raise 0.0 | inheritance tax raised\n",
      "Should government spending be reduced? -> reduce 0.0 | government spending reduced\n",
      "Should children beauty contests be banned? -> ban 0.0 | children beauty contests banned\n",
      "Should the US Electoral college be abolished? -> abolish 0.0 | Electoral college abolished\n",
      "Should social networks be banned? -> ban 0.0 | social networks banned\n",
      "Do we need cash? -> need 0.0 | cash\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "docs = list(nlp.pipe((str(t) for t in topics)))\n",
    "\n",
    "for doc in docs:\n",
    "    root = str(next(doc.sents).root.lemma_)\n",
    "    root_stance = next(doc.sents).root._.blob.polarity\n",
    "    positive = glove_vectors.similarity(root, 'yes') > glove_vectors.similarity(root, 'no')\n",
    "    words = [str(x) for x in doc if zipf_frequency(str(x), 'en') < 5.6 and x.pos_ != 'PUNCT' and str(x) != root]\n",
    "    print (doc, '->', root, root_stance, '|', ' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in topics:\n",
    "    doc = nlp(str(t))\n",
    "    print(list(doc.noun_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import *\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk import pos_tag, word_tokenize, RegexpParser\n",
    "\n",
    "tagged = pos_tag(word_tokenize(topics[2]))\n",
    "\n",
    "#Extract all parts of speech from any text\n",
    "chunker = RegexpParser(\"\"\"\n",
    "                    NP: {<DT>?<JJ>*<NN>} #To extract Noun Phrases\n",
    "                    P: {<IN>}            #To extract Prepositions\n",
    "                    V: {<V.*>}           #To extract Verbs\n",
    "                    PP: {<p> <NP>}       #To extract Prepositional Phrases\n",
    "                    VP: {<V> <NP|PP>*}   #To extract Verb Phrases\n",
    "                    \"\"\")\n",
    "\n",
    "# Print all parts of speech in above sentence\n",
    "output = chunker.parse(tagged)\n",
    "\n",
    "output.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('information_retrieval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c036049273867a5cd7b5ac017e30232e1a1097bbad6cf8a0f460bf5bfef22d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
